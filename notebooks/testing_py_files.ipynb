{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path of the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_pull_and_prep.audio_from_yt import download_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: (Optional) Download audio files from YouTube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using podcasts from youtube in this project as an example. This step is not needed if you already have an mp3 file, skip to step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading audio...\n",
      "Audio downloaded: /Users/rishikeshdhayarkar/rag-audio-indexing/data/testing/audio_0/test3.mp3\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "video_url = \"https://www.youtube.com/watch?v=vcEVgN4eET8\"  # Replace with your video URL\n",
    "video_name = \"test3\"  # Replace with your video name\n",
    "output_dir = project_root+\"/data/testing/audio_0/\"  # Replace with your output directory\n",
    "\n",
    "download_audio(video_url, video_name, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Convert mp3 file to text and generate time stamps for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_pull_and_prep.utils as utils\n",
    "import data_pull_and_prep.data_preparation as data_prep\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert audio to text using Open AI whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rishikeshdhayarkar/rag-audio-indexing/rag-audio-env/lib/python3.12/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/Users/rishikeshdhayarkar/rag-audio-indexing/rag-audio-env/lib/python3.12/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "audio_file_path = project_root+\"/data/testing/audio_0/test3.mp3\"\n",
    "transcription = data_prep.transcribe(audio_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribed output contains an id, piece of converted text, start time and end time in the audio clip for this text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "id: 5\n",
      "text:  what he called new dirt, like they're new dirt, like to make it super like with safety features\n",
      "start time: 26.76\n",
      "end time: 31.44\n"
     ]
    }
   ],
   "source": [
    "print(len(transcription))\n",
    "print(f\"id: {transcription[5][0]}\")\n",
    "print(f\"text: {transcription[5][1]}\")\n",
    "print(f\"start time: {transcription[5][2]}\")\n",
    "print(f\"end time: {transcription[5][3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each such segment(above cell), calculate the time stamp for each character in text by interpolation.\n",
    "\n",
    "But why do we need character level time stamps?\n",
    "Character level timestamps provide the flexibility to create textchunks of any size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_with_char_timestamps = utils.import_pkl_file(project_root+\"/data/audio_1/ivanka_trump_transcription_char_timestamps.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcription_with_char_timestamps = data_prep.map_characters_to_timestamps(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 157283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' ', 0.0),\n",
       " ('T', 0.06449438202247192),\n",
       " ('h', 0.12898876404494383),\n",
       " ('e', 0.19348314606741573),\n",
       " (' ', 0.25797752808988766)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Total number of characters: {len(transcription_with_char_timestamps)}\")\n",
    "transcription_with_char_timestamps[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save character level timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_as_pickle_file(directory=project_root+\"/data/testing/audio_0/\",\n",
    "#                     filename=\"transcription_with_char_timestamps.pkl\",\n",
    "#                     data=transcription_with_char_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create custom chunks using SentenceSplitter from Llamaindex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_chunking_obj = data_prep.CreateCustomTextChunks(transcription_with_char_timestamps)\n",
    "text_chunks_with_timestamps = custom_chunking_obj.create_custom_text_chunks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 42\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of text chunks: {len(text_chunks_with_timestamps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"have like how precious the earth is um I hope that it I hope that it has that\n",
      "effect uh because I you know I think there's a big component to to\n",
      "interplanetary travel that kind of taps into this kind of manifest destiny and\n",
      "clonation like the human desire to conquer territory and expand um the footprint\n",
      "of civilization that sometimes feels much more rooted in like dominance and\n",
      "conquest than curiosity wonder and um and obviously I think there's you know\n",
      "maybe an existential imperative for at some point or a strategic or and security\n",
      "one but um but I hope that what feels inevitable at this moment I mean you know\n",
      "Elon Musk and what he's doing with SpaceX and Jeff Bezos and others it feels\n",
      "like it's not an if it's uh it's a when at this point I hope it also underscores\n",
      "like the need to protect what we have here yeah and it's I hope is the curiosity\n",
      "that drives that exploration and I hope the exploration will give us a deeper\n",
      "appreciation of the thing we have back home and that earth will always be home\n",
      "and it's a home that we protect and celebrate what uh gives you hope about the\n",
      "future of this thing we have going on human civilization the whole thing I think\n",
      "I feel a lot of hope when I'm in nature I feel a lot of hope when I am\n",
      "experiencing people who are good and honest and pure and true and passionate and\n",
      "that's not an uncommon experience so those experiences give me help yeah other\n",
      "humans we're pretty cool I love humanity we're awesome you know not always but\n",
      "um but we're pretty good species yeah for the most part on the whole we do all\n",
      "right we do all right we we create some beautiful stuff and uh I hope we keep\n",
      "creating and I hope you keep creating you've already done a lot of amazing\n",
      "things build a lot of amazing things uh and I hope you keep building and\n",
      "creating and uh doing a lot of beautiful things in this world Ivanka thank you\n",
      "so much for talking today thank you Lex thanks for listening to this\n",
      "conversation with Ivanka Trump the support this podcast please check out our\n",
      "sponsors in the description and now let me leave you with some words from Marcus\n",
      "Aurelius dole on the beauty of life watch the stars and see yourself running\n",
      "with them thank you for listening I hope to see you next time\",\n",
      "(10865.127777777778, 11038.535263157895))\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(str(text_chunks_with_timestamps[-1]), width=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-audio-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
